{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# Path للمشروع\n",
        "project_path = \"/content/drive/MyDrive/HeartProject/data\"\n",
        "\n",
        "# Load data\n",
        "X_scaled_df = pd.read_csv(os.path.join(project_path, \"X_scaled.csv\"))\n",
        "X_final = pd.read_csv(os.path.join(project_path, \"X_final.csv\"))\n",
        "y_binary = pd.read_csv(os.path.join(project_path, \"y_binary.csv\")).squeeze()\n",
        "\n",
        "print(\"✅ Data loaded successfully from Drive\")\n",
        "print(\"Shapes:\", X_scaled_df.shape, X_final.shape, y_binary.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oD4rPYStZ5UA",
        "outputId": "e5c3fe64-a869-43f3-8ade-573c185a929f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✅ Data loaded successfully from Drive\n",
            "Shapes: (303, 18) (303, 6) (303,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvyDo0OaApAC"
      },
      "source": [
        "# Step 4: Supervised Learning Models\n",
        "\n",
        "In this step, we train and evaluate multiple supervised learning models.  \n",
        "To simplify the problem, we first convert the target variable `num` into **binary classes**:\n",
        "- 0 → Healthy (no disease)\n",
        "- 1, 2, 3, 4 → Diseased\n",
        "\n",
        "This is the standard approach in most research papers using the Cleveland dataset.  \n",
        "\n",
        "We will then:\n",
        "1. Train baseline models with default parameters.\n",
        "2. Apply **Hyperparameter Tuning (GridSearchCV)** to improve their performance.\n",
        "\n",
        "Models tested:\n",
        "- Logistic Regression\n",
        "- K-Nearest Neighbors (KNN)\n",
        "- Decision Tree\n",
        "- Random Forest\n",
        "- Support Vector Machine (SVM)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Path in Google Drive\n",
        "drive_path = \"/content/drive/MyDrive/HeartProject/data\"\n",
        "os.makedirs(drive_path, exist_ok=True)\n",
        "\n",
        "# Save final data\n",
        "X_final.to_csv(os.path.join(drive_path, \"X_final.csv\"), index=False)\n",
        "y_binary.to_csv(os.path.join(drive_path, \"y_binary.csv\"), index=False)\n",
        "\n",
        "print(\"✅ Saved X_final.csv and y_binary.csv in Google Drive\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dH48dCbmC8H7",
        "outputId": "904c86f2-daa0-4856-ca96-a0e69e61fe4d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved X_final.csv and y_binary.csv in Google Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAjx0zONhNPV"
      },
      "source": [
        "Binary Target Transformation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFmQfiw4hQ7N"
      },
      "source": [
        "Baseline Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLClpbfnhUTM",
        "outputId": "1fb3b037-f81c-490b-afbb-440e02d291ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Baseline with ALL Features (X_scaled_df) ===\n",
            "Logistic Regression: 0.836\n",
            "KNN: 0.918\n",
            "Decision Tree: 0.869\n",
            "Random Forest: 0.918\n",
            "SVM: 0.852\n",
            "\n",
            "=== Baseline with FINAL Features (X_final) ===\n",
            "Logistic Regression: 0.852\n",
            "KNN: 0.885\n",
            "Decision Tree: 0.738\n",
            "Random Forest: 0.787\n",
            "SVM: 0.869\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# -----------------------\n",
        "# 1. Using ALL features\n",
        "# -----------------------\n",
        "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(\n",
        "    X_scaled_df, y_binary, test_size=0.2, random_state=42, stratify=y_binary\n",
        ")\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, solver=\"liblinear\"),\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"SVM\": SVC()\n",
        "}\n",
        "\n",
        "print(\"=== Baseline with ALL Features (X_scaled_df) ===\")\n",
        "accuracies_all = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_all, y_train_all)\n",
        "    y_pred = model.predict(X_test_all)\n",
        "    acc = accuracy_score(y_test_all, y_pred)\n",
        "    accuracies_all[name] = acc\n",
        "    print(f\"{name}: {acc:.3f}\")\n",
        "\n",
        "# -----------------------\n",
        "# 2. Using FINAL features\n",
        "# -----------------------\n",
        "X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(\n",
        "    X_final, y_binary, test_size=0.2, random_state=42, stratify=y_binary\n",
        ")\n",
        "\n",
        "print(\"\\n=== Baseline with FINAL Features (X_final) ===\")\n",
        "accuracies_final = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_final, y_train_final)\n",
        "    y_pred = model.predict(X_test_final)\n",
        "    acc = accuracy_score(y_test_final, y_pred)\n",
        "    accuracies_final[name] = acc\n",
        "    print(f\"{name}: {acc:.3f}\")\n"
      ]
    }
  ]
}